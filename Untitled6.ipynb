{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f340b6d0-dcf5-4ef1-b58f-c5c6e5d8ce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "[INFO] Loaded model: C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\neurowell_best.keras\n",
      "[INFO] Rebuilt val_ds with 1280 images.\n",
      "[INFO] No training history found; skipped accuracy/loss curves. Tip: use CSVLogger to save logs during training.\n",
      "[SAVE] C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\confusion_matrix.png\n",
      "[SAVE] C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\confusion_matrix_normalized.png\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    MildDemented     0.0000    0.0000    0.0000       179\n",
      "ModerateDemented     0.0000    0.0000    0.0000        13\n",
      "     NonDemented     0.5793    0.8047    0.6736       640\n",
      "VeryMildDemented     0.4348    0.3795    0.4052       448\n",
      "\n",
      "        accuracy                         0.5352      1280\n",
      "       macro avg     0.2535    0.2960    0.2697      1280\n",
      "    weighted avg     0.4418    0.5352    0.4787      1280\n",
      "\n",
      "[SAVE] C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\classification_report.txt\n",
      "[SAVE] C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\gradcam_heatmap.png\n",
      "[SAVE] C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\gradcam_overlay.png\n",
      "Grad-CAM sample → pred: VeryMildDemented  conf: 0.4966\n"
     ]
    }
   ],
   "source": [
    "# ==== One-cell: load model/labels if missing, rebuild val_ds if needed,\n",
    "# ==== then make accuracy/loss plots, confusion matrix heatmaps, Grad-CAM.\n",
    "\n",
    "import os, glob, pickle, json, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# ---------------------- CONFIG / PATHS ----------------------\n",
    "OUT_DIR = Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Your four class folders (exact paths you gave)\n",
    "CLASS_DIRS = [\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\OriginalDataset\\VeryMildDemented\",\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\OriginalDataset\\NonDemented\",\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\OriginalDataset\\ModerateDemented\",\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\OriginalDataset\\MildDemented\",\n",
    "]\n",
    "\n",
    "SEED = 42\n",
    "VAL_SPLIT = 0.2\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH = 32\n",
    "\n",
    "# ---------------------- HELPERS ----------------------\n",
    "def cv2_imread_unicode(path: str) -> np.ndarray:\n",
    "    \"\"\"Unicode-safe read (Windows)\"\"\"\n",
    "    data = np.fromfile(path, dtype=np.uint8)\n",
    "    return cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "\n",
    "def list_images(folder: str):\n",
    "    exts = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tif\", \"*.tiff\"]\n",
    "    files = []\n",
    "    for e in exts:\n",
    "        files.extend(glob.glob(os.path.join(folder, e)))\n",
    "    return sorted(files)\n",
    "\n",
    "def collect_dataset(class_dirs):\n",
    "    paths, labels = [], []\n",
    "    counts = {}\n",
    "    for cdir in class_dirs:\n",
    "        cname = Path(cdir).name\n",
    "        imgs = list_images(cdir)\n",
    "        counts[cname] = len(imgs)\n",
    "        for p in imgs:\n",
    "            paths.append(p)\n",
    "            labels.append(cname)\n",
    "    return paths, labels, counts\n",
    "\n",
    "def build_val_ds_from_paths(val_paths, val_y, nclasses):\n",
    "    def tf_load_and_preprocess(path, label):\n",
    "        def _py(path_tensor):\n",
    "            p = path_tensor.numpy().decode(\"utf-8\")\n",
    "            img_bgr = cv2_imread_unicode(p)\n",
    "            if img_bgr is None:\n",
    "                raise FileNotFoundError(f\"Could not read image: {p}\")\n",
    "            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "            if img_rgb.ndim == 2:\n",
    "                img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_GRAY2RGB)\n",
    "            img_resized = cv2.resize(img_rgb, (IMG_SIZE[1], IMG_SIZE[0]), interpolation=cv2.INTER_AREA)\n",
    "            return img_resized.astype(np.float32)  # 0..255\n",
    "        img = tf.py_function(func=_py, inp=[path], Tout=tf.float32)\n",
    "        img.set_shape((IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "        return img, label\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((val_paths, val_y))\n",
    "    ds = (ds\n",
    "          .map(tf_load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "          .map(lambda x, y: (x, tf.one_hot(y, depth=nclasses, dtype=tf.float32)),\n",
    "               num_parallel_calls=tf.data.AUTOTUNE)\n",
    "          .batch(BATCH)\n",
    "          .prefetch(tf.data.AUTOTUNE))\n",
    "    return ds\n",
    "\n",
    "# ---------------------- LOAD MODEL (if missing) ----------------------\n",
    "model = globals().get(\"model\", None)\n",
    "if model is None:\n",
    "    best_path = OUT_DIR / \"neurowell_best.keras\"\n",
    "    h5_path   = OUT_DIR / \"neurowell_model.h5\"\n",
    "    if best_path.exists():\n",
    "        model = tf.keras.models.load_model(best_path, compile=False)\n",
    "        print(f\"[INFO] Loaded model: {best_path}\")\n",
    "    elif h5_path.exists():\n",
    "        model = tf.keras.models.load_model(h5_path, compile=False)\n",
    "        print(f\"[INFO] Loaded model: {h5_path}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No model found. Expected neurowell_best.keras or neurowell_model.h5 in OUT_DIR.\")\n",
    "\n",
    "# ---------------------- LOAD LABELS (if missing) ----------------------\n",
    "le = globals().get(\"le\", None)\n",
    "if le is None:\n",
    "    pkl_path = OUT_DIR / \"label_encoder.pkl\"\n",
    "    if not pkl_path.exists():\n",
    "        raise FileNotFoundError(f\"label_encoder.pkl not found at {pkl_path}\")\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        pkl = pickle.load(f)\n",
    "    classes_list = [str(c) for c in pkl[\"classes_\"]]\n",
    "    class_to_index = {str(k): int(v) for k, v in pkl[\"class_to_index\"].items()}\n",
    "else:\n",
    "    classes_list = [str(c) for c in le.classes_.tolist()]\n",
    "    class_to_index = {c: i for i, c in enumerate(classes_list)}\n",
    "class_labels = classes_list\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# ---------------------- REBUILD val_ds (if missing) ----------------------\n",
    "val_ds = globals().get(\"val_ds\", None)\n",
    "if val_ds is None:\n",
    "    # Build from your folders with same stratified split\n",
    "    paths, labels, class_counts = collect_dataset(CLASS_DIRS)\n",
    "    if sum(class_counts.values()) == 0:\n",
    "        raise FileNotFoundError(\"No images found in the given folders.\")\n",
    "    y = np.array([class_to_index[str(lbl)] for lbl in labels], dtype=np.int32)\n",
    "    train_paths, val_paths, train_y, val_y = train_test_split(\n",
    "        paths, y, test_size=VAL_SPLIT, random_state=SEED, stratify=y\n",
    "    )\n",
    "    val_ds = build_val_ds_from_paths(val_paths, val_y, num_classes)\n",
    "    print(f\"[INFO] Rebuilt val_ds with {len(val_paths)} images.\")\n",
    "\n",
    "# ---------------------- 1) Accuracy & Loss curves ----------------------\n",
    "# Try 'history' first; if missing, try OUT_DIR/training_log.csv; else skip.\n",
    "hist_obj = globals().get(\"history\", None)\n",
    "if hist_obj is not None and hasattr(hist_obj, \"history\") and hist_obj.history:\n",
    "    hist = hist_obj.history\n",
    "elif (OUT_DIR / \"training_log.csv\").exists():\n",
    "    df = pd.read_csv(OUT_DIR / \"training_log.csv\")\n",
    "    hist = {\n",
    "        \"accuracy\": df[\"accuracy\"].tolist() if \"accuracy\" in df else [],\n",
    "        \"val_accuracy\": df[\"val_accuracy\"].tolist() if \"val_accuracy\" in df else [],\n",
    "        \"loss\": df[\"loss\"].tolist() if \"loss\" in df else [],\n",
    "        \"val_loss\": df[\"val_loss\"].tolist() if \"val_loss\" in df else [],\n",
    "    }\n",
    "else:\n",
    "    hist = None\n",
    "\n",
    "if hist:\n",
    "    epochs_range = range(1, max(len(hist.get(\"accuracy\", [])), len(hist.get(\"val_accuracy\", []))) + 1)\n",
    "\n",
    "    if len(list(epochs_range)) > 0:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        if hist.get(\"accuracy\"):     plt.plot(epochs_range, hist[\"accuracy\"], label=\"Train Acc\")\n",
    "        if hist.get(\"val_accuracy\"): plt.plot(epochs_range, hist[\"val_accuracy\"], label=\"Val Acc\")\n",
    "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Accuracy vs Epochs\"); plt.legend()\n",
    "        acc_curve_path = OUT_DIR / \"accuracy_curve.png\"\n",
    "        plt.tight_layout(); plt.savefig(acc_curve_path, dpi=200); plt.close()\n",
    "        print(f\"[SAVE] {acc_curve_path}\")\n",
    "\n",
    "        plt.figure(figsize=(7,5))\n",
    "        if hist.get(\"loss\"):     plt.plot(epochs_range, hist[\"loss\"], label=\"Train Loss\")\n",
    "        if hist.get(\"val_loss\"): plt.plot(epochs_range, hist[\"val_loss\"], label=\"Val Loss\")\n",
    "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss vs Epochs\"); plt.legend()\n",
    "        loss_curve_path = OUT_DIR / \"loss_curve.png\"\n",
    "        plt.tight_layout(); plt.savefig(loss_curve_path, dpi=200); plt.close()\n",
    "        print(f\"[SAVE] {loss_curve_path}\")\n",
    "    else:\n",
    "        print(\"[INFO] No history values to plot; skipped curves.\")\n",
    "else:\n",
    "    print(\"[INFO] No training history found; skipped accuracy/loss curves. \"\n",
    "          \"Tip: use CSVLogger to save logs during training.\")\n",
    "\n",
    "# ---------------------- 2) Confusion Matrix heatmaps ----------------------\n",
    "all_true, all_pred = [], []\n",
    "for batch_imgs, batch_onehot in val_ds:\n",
    "    probs = model.predict(batch_imgs, verbose=0)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    trues = np.argmax(batch_onehot.numpy(), axis=1)\n",
    "    all_pred.extend(preds.tolist())\n",
    "    all_true.extend(trues.tolist())\n",
    "\n",
    "cm = confusion_matrix(all_true, all_pred, labels=list(range(num_classes)))\n",
    "cm_norm = cm.astype(np.float64) / (cm.sum(axis=1, keepdims=True) + 1e-9)\n",
    "\n",
    "def plot_cm(matrix, labels, title, out_path, normalize=False):\n",
    "    plt.figure(figsize=(7,6))\n",
    "    plt.imshow(matrix, interpolation=\"nearest\", aspect=\"auto\")\n",
    "    plt.title(title); plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    ticks = np.arange(len(labels))\n",
    "    plt.xticks(ticks, labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks, labels)\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = matrix.max() / 2.0 if matrix.size else 0\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            val = format(matrix[i, j], fmt)\n",
    "            plt.text(j, i, val,\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if matrix[i, j] > thresh else \"black\",\n",
    "                     fontsize=9)\n",
    "    plt.ylabel(\"True label\"); plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=220); plt.close()\n",
    "    print(f\"[SAVE] {out_path}\")\n",
    "\n",
    "cm_path  = OUT_DIR / \"confusion_matrix.png\"\n",
    "cmn_path = OUT_DIR / \"confusion_matrix_normalized.png\"\n",
    "plot_cm(cm, class_labels, \"Confusion Matrix\", cm_path, normalize=False)\n",
    "plot_cm(cm_norm, class_labels, \"Confusion Matrix (Normalized)\", cmn_path, normalize=True)\n",
    "\n",
    "rep_txt = classification_report(all_true, all_pred, target_names=class_labels, digits=4)\n",
    "with open(OUT_DIR / \"classification_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(rep_txt)\n",
    "print(rep_txt)\n",
    "print(f\"[SAVE] {OUT_DIR / 'classification_report.txt'}\")\n",
    "\n",
    "# ---------------------- 3) Grad-CAM overlay (one sample) ----------------------\n",
    "try:\n",
    "    # get a sample image from val_ds\n",
    "    for imgs, labels in val_ds.take(1):\n",
    "        sample_img = imgs[0].numpy().astype(np.uint8)  # our pipeline keeps 0..255\n",
    "        sample_onehot = labels[0].numpy()\n",
    "        break\n",
    "\n",
    "    # ensure 224x224x3\n",
    "    if sample_img.ndim == 2:\n",
    "        sample_img = cv2.cvtColor(sample_img, cv2.COLOR_GRAY2RGB)\n",
    "    if sample_img.shape[:2] != (IMG_SIZE[0], IMG_SIZE[1]):\n",
    "        sample_img = cv2.resize(sample_img, (IMG_SIZE[1], IMG_SIZE[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    img_batch = np.expand_dims(sample_img.astype(np.float32), axis=0)  # (1,H,W,3)\n",
    "\n",
    "    # locate last conv layer\n",
    "    last_conv_layer = None\n",
    "    try:\n",
    "        last_conv_layer = model.get_layer(\"top_conv\")  # EfficientNetB0\n",
    "    except:\n",
    "        for layer in reversed(model.layers):\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                last_conv_layer = layer; break\n",
    "    if last_conv_layer is None:\n",
    "        raise RuntimeError(\"No Conv2D layer found for Grad-CAM.\")\n",
    "\n",
    "    grad_model = tf.keras.models.Model([model.inputs], [last_conv_layer.output, model.output])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_batch)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        loss = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)               # (1,h,w,c)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))      # (c,)\n",
    "    conv_outputs = conv_outputs[0]                          # (h,w,c)\n",
    "\n",
    "    heatmap = tf.reduce_sum(conv_outputs * pooled_grads, axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0)\n",
    "    heatmap = heatmap / (tf.reduce_max(heatmap) + 1e-8)\n",
    "    heatmap = heatmap.numpy()\n",
    "\n",
    "    # overlay\n",
    "    heatmap_resized = cv2.resize(heatmap, (IMG_SIZE[1], IMG_SIZE[0]))\n",
    "    heatmap_uint8 = np.uint8(255 * heatmap_resized)\n",
    "    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n",
    "    heatmap_color = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB)\n",
    "    overlay = cv2.addWeighted(sample_img.astype(np.uint8), 0.6, heatmap_color, 0.4, 0)\n",
    "\n",
    "    # save\n",
    "    gradcam_heatmap_path = OUT_DIR / \"gradcam_heatmap.png\"\n",
    "    gradcam_overlay_path = OUT_DIR / \"gradcam_overlay.png\"\n",
    "    plt.imsave(gradcam_heatmap_path, heatmap_resized, cmap=\"jet\")\n",
    "    plt.imsave(gradcam_overlay_path, overlay)\n",
    "    print(f\"[SAVE] {gradcam_heatmap_path}\")\n",
    "    print(f\"[SAVE] {gradcam_overlay_path}\")\n",
    "\n",
    "    probs = model.predict(img_batch, verbose=0)[0]\n",
    "    pred_id = int(np.argmax(probs))\n",
    "    print(f\"Grad-CAM sample → pred: {class_labels[pred_id]}  conf: {probs[pred_id]:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] Grad-CAM skipped: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32708337-9fa0-4d89-8e58-44473c7716ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
