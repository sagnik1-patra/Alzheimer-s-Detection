{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f16f12f-6e31-4ca0-ac4d-9aab76bd4f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "[INFO] Loaded model: C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\neurowell_best.keras\n",
      "[SAVE] C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\augmented_predictions.csv\n",
      "[SAVE] C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\augmented_predictions.json\n",
      "\n",
      "Overall accuracy on provided Augmented folders: 0.3957 (27520 images with known labels)\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    MildDemented     0.6182    0.0076    0.0150      8960\n",
      "ModerateDemented     0.0000    0.0000    0.0000         0\n",
      "     NonDemented     0.4151    0.8852    0.5651      9600\n",
      "VeryMildDemented     0.3349    0.2593    0.2923      8960\n",
      "\n",
      "        accuracy                         0.3957     27520\n",
      "       macro avg     0.3420    0.2880    0.2181     27520\n",
      "    weighted avg     0.4551    0.3957    0.2972     27520\n",
      "\n",
      "[SAVE] C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\augmented_classification_report.txt\n",
      "[SAVE] C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\augmented_confusion_matrix.png\n",
      "[SAVE] C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\augmented_confusion_matrix_normalized.png\n",
      "\n",
      "Sample predictions:\n",
      "                                                                                                                                   file_path       true_label       pred_label  confidence\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\VeryMildDemented\\0001b959-d622-4311-acab-84633370c892.jpg VeryMildDemented      NonDemented    0.484330\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\VeryMildDemented\\0003659d-f8db-4ce4-9230-2ba24506df68.jpg VeryMildDemented VeryMildDemented    0.493947\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\VeryMildDemented\\000a074f-a3a5-4c70-8c94-d7ed7bbe7018.jpg VeryMildDemented VeryMildDemented    0.389309\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\VeryMildDemented\\000b7abc-2404-411d-a46d-467ec55b7795.jpg VeryMildDemented      NonDemented    0.656648\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\VeryMildDemented\\000dea20-ea76-4248-a45d-4119f0bc5ccc.jpg VeryMildDemented      NonDemented    0.636378\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\VeryMildDemented\\000efebb-d4ae-449a-ab10-5e74afa79ef9.jpg VeryMildDemented VeryMildDemented    0.399970\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\VeryMildDemented\\000f173f-ebd5-4ef7-b4d4-6cf80cf754b5.jpg VeryMildDemented      NonDemented    0.391507\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\VeryMildDemented\\0020ed3a-2b5f-4e46-9b96-97484c10a88c.jpg VeryMildDemented VeryMildDemented    0.394058\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\VeryMildDemented\\002149f6-8f25-4b27-9d7a-d059f3966676.jpg VeryMildDemented      NonDemented    0.539602\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\VeryMildDemented\\00255a89-4920-4ac5-b9e9-01430c35ce09.jpg VeryMildDemented      NonDemented    0.535045\n",
      "\n",
      "Done. All outputs saved to: C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\n"
     ]
    }
   ],
   "source": [
    "import os, glob, pickle, warnings, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# ---------------------- CONFIG / PATHS ----------------------\n",
    "AUG_CLASS_DIRS = [\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\VeryMildDemented\",\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\NonDemented\",\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\NonDemented\",  # (dup is ok; we dedupe)\n",
    "    r\"C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\\archive\\AugmentedAlzheimerDataset\\MildDemented\",\n",
    "]\n",
    "\n",
    "OUT_DIR = Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Alzheimer’s Detection\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BATCH = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "SEED = 42\n",
    "\n",
    "# ---------------------- HELPERS (Unicode-safe IO) ----------------------\n",
    "def cv2_imread_unicode(path: str) -> np.ndarray:\n",
    "    \"\"\"Unicode-safe imread for Windows.\"\"\"\n",
    "    data = np.fromfile(path, dtype=np.uint8)\n",
    "    return cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "\n",
    "def list_images(folder: str):\n",
    "    exts = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tif\", \"*.tiff\"]\n",
    "    files = []\n",
    "    for e in exts:\n",
    "        files.extend(glob.glob(os.path.join(folder, e)))\n",
    "    return sorted(files)\n",
    "\n",
    "def collect_dataset(class_dirs):\n",
    "    # dedupe while preserving order\n",
    "    seen = set(); dedup = []\n",
    "    for p in class_dirs:\n",
    "        if p not in seen:\n",
    "            dedup.append(p); seen.add(p)\n",
    "\n",
    "    paths, labels, counts = [], [], {}\n",
    "    for cdir in dedup:\n",
    "        if not Path(cdir).exists():\n",
    "            print(f\"[WARN] Missing folder: {cdir}\")\n",
    "            counts[Path(cdir).name] = 0\n",
    "            continue\n",
    "        cname = Path(cdir).name\n",
    "        imgs = list_images(cdir)\n",
    "        counts[cname] = len(imgs)\n",
    "        for p in imgs:\n",
    "            paths.append(p); labels.append(cname)\n",
    "    return paths, labels, counts, dedup\n",
    "\n",
    "def build_tf_dataset(file_paths, img_size, batch_size):\n",
    "    def tf_load(path):\n",
    "        def _py(p):\n",
    "            p = p.numpy().decode(\"utf-8\")\n",
    "            img_bgr = cv2_imread_unicode(p)\n",
    "            if img_bgr is None:\n",
    "                raise FileNotFoundError(f\"Could not read: {p}\")\n",
    "            img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "            if img.ndim == 2:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            img = cv2.resize(img, (img_size[1], img_size[0]), interpolation=cv2.INTER_AREA)\n",
    "            return img.astype(np.float32)  # 0..255\n",
    "        img = tf.py_function(_py, [path], Tout=tf.float32)\n",
    "        img.set_shape((img_size[0], img_size[1], 3))\n",
    "        return img\n",
    "    ds = tf.data.Dataset.from_tensor_slices(file_paths)\n",
    "    ds = ds.map(tf_load, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# ---------------------- LOAD MODEL & LABELS ----------------------\n",
    "# Try best checkpoint, then h5\n",
    "model_path_best = OUT_DIR / \"neurowell_best.keras\"\n",
    "model_path_h5   = OUT_DIR / \"neurowell_model.h5\"\n",
    "if model_path_best.exists():\n",
    "    model = tf.keras.models.load_model(model_path_best, compile=False)\n",
    "    print(f\"[INFO] Loaded model: {model_path_best}\")\n",
    "elif model_path_h5.exists():\n",
    "    model = tf.keras.models.load_model(model_path_h5, compile=False)\n",
    "    print(f\"[INFO] Loaded model: {model_path_h5}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"No model found in OUT_DIR (neurowell_best.keras or neurowell_model.h5).\")\n",
    "\n",
    "num_classes = int(model.output_shape[-1])\n",
    "\n",
    "# Load label encoder if present (preferred for correct class order)\n",
    "le_path = OUT_DIR / \"label_encoder.pkl\"\n",
    "label_order = None\n",
    "if le_path.exists():\n",
    "    with open(le_path, \"rb\") as f:\n",
    "        le_obj = pickle.load(f)\n",
    "    label_order = [str(c) for c in le_obj.get(\"classes_\", [])]\n",
    "    if len(label_order) != num_classes:\n",
    "        print(f\"[WARN] Label encoder classes ({len(label_order)}) \"\n",
    "              f\"!= model outputs ({num_classes}). Will fallback if needed.\")\n",
    "else:\n",
    "    print(\"[WARN] label_encoder.pkl not found — will infer labels from folder names.\")\n",
    "\n",
    "# ---------------------- BUILD FILE LIST ----------------------\n",
    "file_paths, true_labels, class_counts, used_dirs = collect_dataset(AUG_CLASS_DIRS)\n",
    "if len(file_paths) == 0:\n",
    "    raise FileNotFoundError(\"No images found in the provided Augmented folders.\")\n",
    "\n",
    "# If no label encoder, infer deterministic class order\n",
    "if label_order is None or len(label_order) != num_classes:\n",
    "    # Sort by name; if mismatch with model, we still use them for reporting\n",
    "    label_order = sorted(set(true_labels))\n",
    "    if len(label_order) != num_classes:\n",
    "        print(f\"[WARN] Dataset classes ({len(label_order)}) != model outputs ({num_classes}). \"\n",
    "              f\"Proceeding with mapped indices; predictions will still be correct per index, \"\n",
    "              f\"but labels may not align with training order.\")\n",
    "class_to_index = {c: i for i, c in enumerate(label_order)}\n",
    "\n",
    "# Map each true label to index (unknown labels -> -1)\n",
    "true_idx = np.array([class_to_index.get(lbl, -1) for lbl in true_labels], dtype=np.int32)\n",
    "\n",
    "# ---------------------- PREDICT ----------------------\n",
    "predict_ds = build_tf_dataset(file_paths, IMG_SIZE, BATCH)\n",
    "probs_list = []\n",
    "for batch in predict_ds:\n",
    "    probs = model.predict(batch, verbose=0)\n",
    "    probs_list.append(probs)\n",
    "probs_all = np.vstack(probs_list)  # shape (N, num_classes)\n",
    "pred_idx = probs_all.argmax(axis=1)\n",
    "conf_all = probs_all.max(axis=1)\n",
    "\n",
    "# Map indices to label names (best-effort)\n",
    "def idx_to_label(i):\n",
    "    if 0 <= i < len(label_order):\n",
    "        return label_order[i]\n",
    "    return f\"class_{i}\"\n",
    "\n",
    "pred_labels = [idx_to_label(i) for i in pred_idx]\n",
    "\n",
    "# ---------------------- RESULTS: CSV/JSON & METRICS ----------------------\n",
    "results_df = pd.DataFrame({\n",
    "    \"file_path\": file_paths,\n",
    "    \"true_label\": true_labels,\n",
    "    \"true_idx\": true_idx,\n",
    "    \"pred_label\": pred_labels,\n",
    "    \"pred_idx\": pred_idx,\n",
    "    \"confidence\": conf_all\n",
    "})\n",
    "\n",
    "# Save predictions\n",
    "pred_csv = OUT_DIR / \"augmented_predictions.csv\"\n",
    "pred_json = OUT_DIR / \"augmented_predictions.json\"\n",
    "results_df.to_csv(pred_csv, index=False, encoding=\"utf-8-sig\")\n",
    "results_df.to_json(pred_json, orient=\"records\", force_ascii=False, indent=2)\n",
    "print(f\"[SAVE] {pred_csv}\")\n",
    "print(f\"[SAVE] {pred_json}\")\n",
    "\n",
    "# Compute metrics only on rows with valid true_idx\n",
    "mask_valid = results_df[\"true_idx\"] >= 0\n",
    "y_true = results_df.loc[mask_valid, \"true_idx\"].to_numpy()\n",
    "y_pred = results_df.loc[mask_valid, \"pred_idx\"].to_numpy()\n",
    "\n",
    "if len(y_true) > 0:\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\nOverall accuracy on provided Augmented folders: {acc:.4f} \"\n",
    "          f\"({mask_valid.sum()} images with known labels)\")\n",
    "\n",
    "    # Classification report\n",
    "    # Ensure all classes (0..num_classes-1) have a target name\n",
    "    target_names = [idx_to_label(i) for i in range(num_classes)]\n",
    "    report_txt = classification_report(\n",
    "        y_true, y_pred, labels=list(range(num_classes)),\n",
    "        target_names=target_names, digits=4, zero_division=0\n",
    "    )\n",
    "    rep_path = OUT_DIR / \"augmented_classification_report.txt\"\n",
    "    with open(rep_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report_txt)\n",
    "    print(report_txt)\n",
    "    print(f\"[SAVE] {rep_path}\")\n",
    "\n",
    "    # Confusion matrices (raw + normalized)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "    cm_norm = cm.astype(np.float64) / (cm.sum(axis=1, keepdims=True) + 1e-9)\n",
    "\n",
    "    def plot_cm(matrix, labels, title, out_path, normalize=False):\n",
    "        plt.figure(figsize=(7,6))\n",
    "        plt.imshow(matrix, interpolation=\"nearest\", aspect=\"auto\")\n",
    "        plt.title(title); plt.colorbar(fraction=0.046, pad=0.04)\n",
    "        ticks = np.arange(len(labels))\n",
    "        plt.xticks(ticks, labels, rotation=45, ha=\"right\")\n",
    "        plt.yticks(ticks, labels)\n",
    "        fmt = \".2f\" if normalize else \"d\"\n",
    "        thresh = matrix.max() / 2.0 if matrix.size else 0\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(matrix.shape[1]):\n",
    "                val = format(matrix[i, j], fmt)\n",
    "                plt.text(j, i, val,\n",
    "                         ha=\"center\", va=\"center\",\n",
    "                         color=\"white\" if matrix[i, j] > thresh else \"black\",\n",
    "                         fontsize=9)\n",
    "        plt.ylabel(\"True label\"); plt.xlabel(\"Predicted label\")\n",
    "        plt.tight_layout(); plt.savefig(out_path, dpi=220); plt.close()\n",
    "        print(f\"[SAVE] {out_path}\")\n",
    "\n",
    "    cm_path  = OUT_DIR / \"augmented_confusion_matrix.png\"\n",
    "    cmn_path = OUT_DIR / \"augmented_confusion_matrix_normalized.png\"\n",
    "    plot_cm(cm, target_names, \"Confusion Matrix (Augmented)\", cm_path, normalize=False)\n",
    "    plot_cm(cm_norm, target_names, \"Confusion Matrix (Augmented, Normalized)\", cmn_path, normalize=True)\n",
    "else:\n",
    "    print(\"\\nNo valid true labels to score against (label mapping mismatch). \"\n",
    "          \"Predictions CSV/JSON are still saved.\")\n",
    "\n",
    "# ---------------------- SAMPLE PREVIEW ----------------------\n",
    "print(\"\\nSample predictions:\")\n",
    "display_cols = [\"file_path\", \"true_label\", \"pred_label\", \"confidence\"]\n",
    "print(results_df[display_cols].head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nDone. All outputs saved to:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34fb5dd-02a1-4593-8f8e-4f4679a03f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
